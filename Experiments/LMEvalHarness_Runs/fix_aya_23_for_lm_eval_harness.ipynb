{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "DO NOT RUN THIS NOTEBOOK WITHOUT UNDERSTANDING THE CONSEQUENCES",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDO NOT RUN THIS NOTEBOOK WITHOUT UNDERSTANDING THE CONSEQUENCES\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: DO NOT RUN THIS NOTEBOOK WITHOUT UNDERSTANDING THE CONSEQUENCES"
     ]
    }
   ],
   "source": [
    "raise Exception(\"DO NOT RUN THIS NOTEBOOK WITHOUT UNDERSTANDING THE CONSEQUENCES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "RERUNNING THIS NOTEBOOK MULTIPLE TIMES CAN CAUSE UNEXPECTED BEHAVIOR",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRERUNNING THIS NOTEBOOK MULTIPLE TIMES CAN CAUSE UNEXPECTED BEHAVIOR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: RERUNNING THIS NOTEBOOK MULTIPLE TIMES CAN CAUSE UNEXPECTED BEHAVIOR"
     ]
    }
   ],
   "source": [
    "raise Exception(\"RERUNNING THIS NOTEBOOK MULTIPLE TIMES CAN CAUSE UNEXPECTED BEHAVIOR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "COMMENT THESE WARNINGS AT YOUR OWN RISK",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOMMENT THESE WARNINGS AT YOUR OWN RISK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: COMMENT THESE WARNINGS AT YOUR OWN RISK"
     ]
    }
   ],
   "source": [
    "raise Exception(\"COMMENT THESE WARNINGS AT YOUR OWN RISK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ WARNINGS ABOVE\n",
    "\n",
    "This notebook fixes an issue with the tokenizer config which makes it non-usable in the eval harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/NS/llm-1/nobackup/afkhan/Model_Saves/aya-23-8B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer_config.json\n",
    "with open(os.path.join(model_path, 'tokenizer_config.json'), 'r') as f:\n",
    "    tokenizer_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_template = tokenizer_config['chat_template'][0]['template']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_config['chat_template'] = default_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename tokenizer_config.json to tokenizer_config_legacy.json\n",
    "os.rename(os.path.join(model_path, 'tokenizer_config.json'), os.path.join(model_path, 'tokenizer_config_legacy.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save current version as tokenizer_config.json\n",
    "with open(os.path.join(model_path, 'tokenizer_config.json'), 'w') as f:\n",
    "    json.dump(tokenizer_config, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if the file is correct now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer_config.json\n",
    "with open(os.path.join(model_path, 'tokenizer_config.json'), 'r') as f:\n",
    "    tokenizer_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'add_bos_token': True,\n",
       " 'add_eos_token': False,\n",
       " 'add_prefix_space': False,\n",
       " 'added_tokens_decoder': {'0': {'content': '<PAD>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': True},\n",
       "  '1': {'content': '<UNK>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': True},\n",
       "  '2': {'content': '<CLS>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': True},\n",
       "  '3': {'content': '<SEP>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': True},\n",
       "  '4': {'content': '<MASK_TOKEN>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': True},\n",
       "  '5': {'content': '<BOS_TOKEN>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': True},\n",
       "  '6': {'content': '<EOS_TOKEN>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': True},\n",
       "  '7': {'content': '<EOP_TOKEN>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': True},\n",
       "  '255000': {'content': '<|START_OF_TURN_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255001': {'content': '<|END_OF_TURN_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': True},\n",
       "  '255002': {'content': '<|YES_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255003': {'content': '<|NO_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255004': {'content': '<|GOOD_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255005': {'content': '<|BAD_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255006': {'content': '<|USER_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255007': {'content': '<|CHATBOT_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255008': {'content': '<|SYSTEM_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255009': {'content': '<|USER_0_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255010': {'content': '<|USER_1_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255011': {'content': '<|USER_2_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255012': {'content': '<|USER_3_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255013': {'content': '<|USER_4_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255014': {'content': '<|USER_5_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255015': {'content': '<|USER_6_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255016': {'content': '<|USER_7_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255017': {'content': '<|USER_8_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255018': {'content': '<|USER_9_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255019': {'content': '<|EXTRA_0_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255020': {'content': '<|EXTRA_1_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255021': {'content': '<|EXTRA_2_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255022': {'content': '<|EXTRA_3_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255023': {'content': '<|EXTRA_4_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255024': {'content': '<|EXTRA_5_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255025': {'content': '<|EXTRA_6_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255026': {'content': '<|EXTRA_7_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255027': {'content': '<|EXTRA_8_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False},\n",
       "  '255028': {'content': '<|EXTRA_9_TOKEN|>',\n",
       "   'lstrip': False,\n",
       "   'normalized': False,\n",
       "   'rstrip': False,\n",
       "   'single_word': False,\n",
       "   'special': False}},\n",
       " 'bos_token': '<BOS_TOKEN>',\n",
       " 'chat_template': \"{{ bos_token }}{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% elif false == true %}{% set loop_messages = messages %}{% set system_message = 'You are Command-R, a brilliant, sophisticated, AI-assistant trained to assist human users by providing thorough responses. You are trained by Cohere.' %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% if system_message != false %}{{ '<|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>' + system_message + '<|END_OF_TURN_TOKEN|>' }}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<|START_OF_TURN_TOKEN|><|USER_TOKEN|>' + content.strip() + '<|END_OF_TURN_TOKEN|>' }}{% elif message['role'] == 'assistant' %}{{ '<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>'  + content.strip() + '<|END_OF_TURN_TOKEN|>' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>' }}{% endif %}\",\n",
       " 'clean_up_tokenization_spaces': False,\n",
       " 'eos_token': '<|END_OF_TURN_TOKEN|>',\n",
       " 'legacy': True,\n",
       " 'merges_file': None,\n",
       " 'model_max_length': 1000000000000000019884624838656,\n",
       " 'pad_token': '<PAD>',\n",
       " 'sp_model_kwargs': {},\n",
       " 'spaces_between_special_tokens': False,\n",
       " 'tokenizer_class': 'CohereTokenizer',\n",
       " 'unk_token': None,\n",
       " 'use_default_system_prompt': False,\n",
       " 'vocab_file': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsdp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
