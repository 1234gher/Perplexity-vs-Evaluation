lm_eval --model hf --model_args pretrained='/NS/llm-1/nobackup/afkhan/Model_Saves/aya-23-35B' --tasks hellaswag_ar_chat_ppl,hellaswag_bn_chat_ppl,hellaswag_ca_chat_ppl,hellaswag_da_chat_ppl,hellaswag_de_chat_ppl,hellaswag_es_chat_ppl,hellaswag_eu_chat_ppl,hellaswag_fr_chat_ppl,hellaswag_gu_chat_ppl,hellaswag_hi_chat_ppl,hellaswag_hr_chat_ppl,hellaswag_hu_chat_ppl,hellaswag_hy_chat_ppl,hellaswag_id_chat_ppl,hellaswag_it_chat_ppl,hellaswag_kn_chat_ppl,hellaswag_ml_chat_ppl,hellaswag_mr_chat_ppl,hellaswag_ne_chat_ppl,hellaswag_nl_chat_ppl,hellaswag_pt_chat_ppl,hellaswag_ro_chat_ppl,hellaswag_ru_chat_ppl,hellaswag_sk_chat_ppl,hellaswag_sr_chat_ppl,hellaswag_sv_chat_ppl,hellaswag_ta_chat_ppl,hellaswag_te_chat_ppl,hellaswag_uk_chat_ppl,hellaswag_vi_chat_ppl,hellaswag_chat_ppl --batch_size auto --write_out --seed 42 --output_path /NS/llm-1/work/afkhan/Perplexity-vs-Evaluation/Experiments/Perplexity_Runs/aya_23_35B_chat_ppl_hellaswag_with_okapi_with_template --log_samples --wandb_args project=PPL_vs_Eval,name=aya_23_35B_chat_ppl_hellaswag_with_okapi_with_template >> /NS/llm-1/work/afkhan/Perplexity-vs-Evaluation/Experiments/Perplexity_Runs/Logs/aya_23_35B_chat_ppl_hellaswag_with_okapi_with_template.log
