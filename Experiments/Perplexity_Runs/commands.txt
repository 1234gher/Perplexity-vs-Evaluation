lm_eval --model hf --model_args pretrained='/NS/llm-1/nobackup/afkhan/Model_Saves/aya-23-8B' --tasks custom_ppl_task --device cuda:0 --batch_size auto --write_out --seed 42 --output_path /NS/llm-1/work/afkhan/Perplexity-vs-Evaluation/Experiments/Perplexity_Runs/aya-23-8b-custom_ppl_task --log_samples --wandb_args project=PPL_vs_Eval,name=aya-23-8b-custom_ppl_task >> /NS/llm-1/work/afkhan/Perplexity-vs-Evaluation/Experiments/Perplexity_Runs/Logs/aya-23-8b-custom_ppl_task.log