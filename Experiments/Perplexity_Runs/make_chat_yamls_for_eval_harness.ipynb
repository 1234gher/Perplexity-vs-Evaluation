{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "harness_path = '/NS/llm-1/work/afkhan/lm-evaluation-harness/lm_eval/tasks/custom_ppl_task/'\n",
    "yaml_path = '/NS/llm-1/work/afkhan/Perplexity-vs-Evaluation/Experiments/Perplexity_Runs/EvalHarness_Chat_YAMLs/'\n",
    "data_path = '/NS/llm-1/work/afkhan/Perplexity-vs-Evaluation/Experiments/Perplexity_Runs/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = os.listdir(data_path)\n",
    "# keep those which contain _no_template\n",
    "data_files = [f for f in data_files if '_no_template' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task: custom_ppl_task\n",
    "# output_type: loglikelihood_rolling\n",
    "# training_split: null\n",
    "# validation_split: null\n",
    "# test_split: train\n",
    "# doc_to_text: \"\"\n",
    "# doc_to_target: !function preprocess_wikitext.apply_aya_chat_template\n",
    "# process_results: !function preprocess_wikitext.process_results\n",
    "# should_decontaminate: false\n",
    "# doc_to_decontamination_query: None\n",
    "# metric_list:\n",
    "#   - metric: word_perplexity\n",
    "#   - metric: byte_perplexity\n",
    "#   - metric: bits_per_byte\n",
    "\n",
    "# dataset_path: json\n",
    "# dataset_name: null\n",
    "\n",
    "# dataset_kwargs:\n",
    "#   data_files: /NS/llm-1/work/afkhan/Perplexity-vs-Evaluation/Experiments/Perplexity_Runs/Data/hellaswag_okapi_no_template_aya_23_8B.jsonl\n",
    "#   trust_remote_code: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_aya_chat_template(doc):\n",
    "    base_str = doc['text']\n",
    "    # Example Output - <BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Roof shingle removal: A man is sitting on a roof. He<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>\n",
    "    template_applied_str = '<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>' + base_str + '<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>'\n",
    "    return template_applied_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDumper(yaml.SafeDumper):\n",
    "#     def represent_function(self, value):\n",
    "#         return self.represent_scalar('!function', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionTag(yaml.YAMLObject):\n",
    "    yaml_tag = '!function'\n",
    "    \n",
    "    def __init__(self, function_name):\n",
    "        self.function_name = function_name\n",
    "\n",
    "    @classmethod\n",
    "    def to_yaml(cls, dumper, data):\n",
    "        # Create a scalar node with the function tag and the function name\n",
    "        return dumper.represent_scalar(cls.yaml_tag, data.function_name, style=None)\n",
    "\n",
    "# def make_yaml(task_name, data_files, save_path):\n",
    "#     task = {\n",
    "#         'task': task_name,\n",
    "#         'output_type': 'loglikelihood_rolling',\n",
    "#         'training_split': None,\n",
    "#         'validation_split': None,\n",
    "#         'test_split': 'train',\n",
    "#         'doc_to_text': FunctionTag(\"preprocess_wikitext.apply_aya_chat_template\"),\n",
    "#         'process_results': FunctionTag(\"preprocess_wikitext.process_results\"),\n",
    "#         'should_decontaminate': False,\n",
    "#         'doc_to_decontamination_query': None,\n",
    "#         'metric_list': [\n",
    "#             {'metric': 'word_perplexity'},\n",
    "#             {'metric': 'byte_perplexity'},\n",
    "#             {'metric': 'bits_per_byte'}\n",
    "#         ],\n",
    "#         'dataset_path': 'json',\n",
    "#         'dataset_name': None,\n",
    "#         'dataset_kwargs': {\n",
    "#             'data_files': data_files,\n",
    "#             'trust_remote_code': True\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "#     with open(save_path, 'w') as file:\n",
    "#         yaml.dump(task, file, default_flow_style=False, default_style=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_yaml(task_name, data_files, save_path):\n",
    "    task = {\n",
    "        'task': task_name,\n",
    "        'output_type': 'loglikelihood_rolling',\n",
    "        'training_split': None,\n",
    "        'validation_split': None,\n",
    "        'test_split': 'train',\n",
    "        'doc_to_text': \"\",\n",
    "        'doc_to_target': FunctionTag(\"preprocess_wikitext.apply_aya_chat_template\"),\n",
    "        'process_results': FunctionTag(\"preprocess_wikitext.process_results\"),\n",
    "        'should_decontaminate': False,\n",
    "        'doc_to_decontamination_query': None,\n",
    "        'metric_list': [\n",
    "            {'metric': 'word_perplexity'},\n",
    "            {'metric': 'byte_perplexity'},\n",
    "            {'metric': 'bits_per_byte'}\n",
    "        ],\n",
    "        'dataset_path': 'json',\n",
    "        'dataset_name': None,\n",
    "        'dataset_kwargs': {\n",
    "            'data_files': data_files,\n",
    "            'trust_remote_code': True\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(save_path, 'w') as file:\n",
    "        yaml.dump(task, file, default_flow_style=False, default_style=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CustomDumper.add_representer(str, CustomDumper.represent_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d_file in data_files:\n",
    "    # Remove samples_ prefix\n",
    "    file_name = d_file.replace('samples_', '')\n",
    "    # Split on _2024\n",
    "    file_name = file_name.split('_2024')[0]\n",
    "    file_name += '_chat_ppl'\n",
    "    make_yaml(file_name, os.path.join(data_path, d_file), os.path.join(yaml_path, f'{file_name}.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all the yaml files to the harness path\n",
    "import shutil\n",
    "for yaml_file in os.listdir(yaml_path):\n",
    "    shutil.copyfile(os.path.join(yaml_path, yaml_file), os.path.join(harness_path, yaml_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
